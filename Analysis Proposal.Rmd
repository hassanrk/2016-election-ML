---
title: "Analysis Proposal [Group: High Expectasians]"
author: "Hassan Rahim Kamil (rahimka2), Weiliang Hu (whu17)"
date: "11/5/2018"
output:
  html_document:
    df_print: paged
---

# Sentiment Analysis of Trump's and Clinton's 2016 Tweets and Predicting Public Opinions

***

```{r setup-chunk, message = FALSE, warning = FALSE, echo = F}
pkg_list = c("tidyverse", "caret", "MASS", "tm", "tidytext", "syuzhet", "rtweet", "twitteR", "SnowballC", "devtools", "gtrendsR", "jsonlite", "rpart.plot", "pollstR", "RSentiment", "broom", "quanteda")
mia_pkgs = pkg_list[!(pkg_list %in% installed.packages()[,"Package"])]
if(length(mia_pkgs) > 0) install.packages(mia_pkgs)
loaded_pkgs = lapply(pkg_list, require, character.only=TRUE)
```

```{r reading data, cache = T, echo = F}
tweets = read.csv("tweets.csv") 
polls = read.csv("presidential_polls.csv")

hillary = read.csv("hillary-tweets.csv", header = T, sep = ">")
trump = fromJSON("trump-tweets.json")

```



## Introduction 

Microblogging is becoming more and more commonplace among today's generation. In fact, interactions with some type of online platforms or service such as Facebook, Twitter or Google leave traces of data that show a record of behavior or actions. As Davidowitz put it in his book *Everybody Lies*: "The everyday act of typing a word or phrase into a compact, rectangular white box leaves a small trace of truth that, when multiplied by millions, eventually reveals profound realities." To statisticians, this quote faintly reminds of the many statistical ideas that could be put to the test.

An emerging role of online platforms has been in the political context. As such, our research topic would be to predict political outcomes with a preferred dataset that is in line with our hypothesis and allows us to scientifically control for many variable.

> Hypothesis: We could use sentiments on social media to predict public opinions as a proxy for political outcomes.

The scope of the preferred dataset(s) that we are looking into include observations 

- whose geolocations match those of the political outcomes of interest.
- represent the voter base. And;
- are longitudinal. 

According to [Google Trends](https://trends.google.com/trends/story/election2016), the keywords most searched on Google during the 2016 election are "Abortion", "Immigration", "Race Issues", "Economy", "Affordable Care Act", "ISIS", "Climate Change", "National Debt", "Gun Control" and "Voting System." Using `gtrendsR`, we randomly picked five of those keywords and queried its search hits by setting `geo = "US"` to prevent bias.

```{r trend 1, cache = T, warning = F}
trend1 = gtrends(c("immigration", "abortion", "economy", "gun control", "terrorism"), geo = "US", time = "2016-01-01 2016-12-31")

plot(trend1)
```

Lo and behold, the trends do not differ much when we queried for Trump and Hillary.

```{r trend 2, cache = T}
trend2 = gtrends(c("hillary", "trump"), geo = "US", time = "2016-01-01 2016-09-28")


trend2$interest_over_time

plot(trend2)
```

The trends are calculated on a weekly basis. How these trends are calculated can be viewed [here](https://support.google.com/trends/answer/4365533?hl=en). We see that these trends look more similar around mid-campaign.

Another popular measure of public opinions are by using polls. To that end, we queried [HuffPost Pollster](https://elections.huffingtonpost.com/pollster), a poll that aggregates every poll that claims to represent the population using `pollstR`.

```{r pollster, eval = F}
slug = "2016-general-election-trump-vs-clinton"
polls = pollster_charts_polls(slug) %>% .[["content"]]
trendlines = pollster_charts_trendlines(slug)[["content"]]

```

```{r, echo = F, eval = F}

# Scatterplot

.data <- gather(polls, response, value,
                Favorable, Unfavorable, Undecided) %>%
  mutate(value = if_else(is.na(value), 0, value))
ggplot() +
  geom_point(data = .data,
             aes(x = end_date, y = value, color = response),
             alpha = 0.5) +
  geom_smooth(data = .data, method = "loess", se = FALSE,
              aes(x = end_date, y = value, color = response))

# Trendlines

ggplot() +
  geom_point(data = .data,
             mapping = aes(x = end_date, y = value, color = response),
             alpha = 0.5) +
  geom_line(data = trendlines,
            mapping = aes(x = date, y = value, color = label), size = 1.5)



```

We hypothesize that these trends are invoked by the use of sentiments from both political candidates during their campaigns either through speech or social media. Using the trends as the labels and the sentiments as the features, we could attempt to build a model to find out their interactions.

Some packages that we **may** use for this project:

```
tidyverse: 
A collection of R packages designed for data science. Useful for reading, wrangling and visualizing data.

caret:
A package to execute ML algorithms in R.

MASS:
A package that has functions and datasets to support Venables and Ripley, "Modern Applied Statistics with S" (4th edition, 2002).

tm: 
A package for text mining.

gtrendsR:
A package to query Google Trends.

pollstR:
A package to query Huffpost Pollster.

syuzhet, tidytext, RSentiment, SentimentAnalysis:
A collection of packages for sentiment analysis.

rtweet, TwitteR:
Packages to scrape from Twitter API.

broom:
A package that summarizes key information about statistical objects in tidy tibbles for textual data.

quanteda:
A package for quantitative analysis of textual data

```


***

## Method/ Approach/ Design

For demonstration of the methods that we plan to use: 

#### 1) Scraping Twitter API and Cleaning Data

As observed from the trends, we plan to extract tweets where search hits of Trump and Hillary match those of the top keywords on Google Trends. To that end, we will be scraping tweets from `@realDonaldTrump` and `@HillaryClinton`. This is easily done with either `twitteR` or `rtweet` by querying the info needed from the Twitter API. However, as of July 2018, a Twitter developer account needs to be made prior before we could provide a token to access the Twitter API. As of writing this paragraph, Hassan is waiting for his Twitter developer account to be approved.

For demonstration (and a backup dataset), we have obtained a dataset from [Kaggle](https://www.kaggle.com/benhamner/clinton-trump-tweets) of Trump's and Clinton's tweets from 01/01/2016 to 09/28/2016. Our then-scraped dataset will more or less look like the backup dataset. An overview of the dataset:


|         Features        |           Description           |
|-------------------------|---------------------------------|
| handle                  | Twitter handle name             |
| text                    | Tweets                          |
| is_retweet              | Whether the tweet was retweeted |
| original_author         | Original author                 |
| time                    | Timestamp                       |
| in_reply_to_screen_name | -                               |
| in_reply_to_status_id   | -                               |
| in_reply_to_user_id     | -                               |
| is_quote_status         | Whether the tweet was quoted    |
| lang                    | Twitter's guess at language     |
| retweet_count           | Retweet count                   |
| favorite_count          | Favorite count                  |
| longitude               | Longitude                       |
| latitude                | Latitude                        |
| place_id                | Place id                        |
| place_full_name         | Place full name                 |
| place_name              | Place name                      |
| place_type              | Place type                      |
| place_country_code      | Country code                    |
| place_country           | Country                         |
| place_contained_within  | Place contained within          |
| place_attributes        | Place attributes                |
| place_bounding_box      | Place bounding box              |
| source_url              | Tweet source url                |
| truncated               | Whether it is truncated         |
| entities                | a JSON object                   |
| extended_entities       | Another JSON object             |

The dimensions of the dataset:

```{r data, echo = F}
dim(tweets)
```

First five observations of both candidates:

`@HillaryClinton`:

```{r hillary, echo = F}

tweets %>% .[tweets$handle == "HillaryClinton", ] %>% head(5)

```

`@realDonaldTrump`:

```{r trump, echo = F}

tweets %>% .[tweets$handle == "realDonaldTrump", ] %>% head(5)

```

In sentiment analysis, we would treat the texts as a corpus object and clean them by using the function `tm_map()` from the `tm` package until we are only left with the sentiments.

```{r creating corpus, echo = F}

corpus = as.character(tweets[, "text"]) %>% VectorSource() %>% Corpus()

corpus
```

```{r cleaning, results = "hide", warning= F}

cleaned_corpus = tm_map(corpus, tolower) %>%
  tm_map(PlainTextDocument) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stripWhitespace)

cleaned_corpus

```

Alternatively, another approach is to use the `tidytext` or `quanteda` package to clean the corpus object.

For this, since the labels are defined weekly, we have to make sure that the strings are concatenated weekly before only the sentiments are kept. To that end, we could achieve this by using the functional `tapply()` and the function `string_c` (from the `stringr` package) after we have processed the timestamps to become a `week` factor so that the variables match the labels.


#### 2) Analyzing the Textual Data

After obtaining only the sentiments, we would transform them into a Document-Term Matrix, which calculates the frequencies at which the sentiments appear at each observation. A document-term matrix can be performed from `DocumentTermMatrix()` function from the `tm` package or the `cast_dtm()` function or `cast_dtm()` from `tidytext`, and that we will use whichever one is more "R-friendly", i.e. whose object is easier to transform to become R-readable so that we could perform an analysis with it.

For example, we have the following two texts:

```
[1]
"I like STAT432"

[2]
"I hate STAT432"
```

A document-term matrix would show:

| id | I | hate | like | STAT432 |
|----|---|------|------|---------|
|  1 | 1 |   0  |   1  |    1    |
|  2 | 1 |   1  |   0  |    1    |

It is important that we only obtain the sentiments so that we could treat the frequencies as our predictors before performing our analysis.

Furthermore, we would define a popularity vector $\mathbf{P}$ as

$$\mathbf{P} = \frac{|\{w_i : w_i \in W\} |_t}{|W|_t} \in \{[0, 1]\}_{t=1}^n$$
, which is approximately how the Google Trend's search hits are defined after adjusting for time.

We would want to estimate $\mathbf{\hat{P}}$ using the sentiments as the predictors. We could perform a few analyses with this setup:

(a) **Logistic Regression**

Since the $\mathbf{P}$ vector is between 0 and 1 and that the popularity metric can be seen as a probability, we could perform a logistic regression to explore the trend of the search query. The `broom` package allows us to perform such task:

```{r, echo = F, message = F}
data("data_corpus_inaugural", package = "quanteda")

library(dplyr)
library(tidyr)

freq_d = tidy(data_corpus_inaugural) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(Year, word) %>%
  complete(Year, word, fill = list(n = 0)) %>%
  group_by(Year) %>%
  mutate(year_total = sum(n),
         percent = n / year_total) %>%
  ungroup()
```


```{r}
logit1 = freq_d %>%
  group_by(word) %>%
  filter(sum(n) > 50) %>%
  do(tidy(glm(cbind(n, year_total - n) ~ Year, data = .,
              family = "binomial"))) %>%
  ungroup() %>%
  filter(term == "Year")

logit1
```

The `broom` package allows us to produce a summary output of the frequency of each word from the logistic regression. We can this analysis to get the crests and troughs of the trends that we are interested in analyzing.

(b) **Lasso or Ridge Regression**

In the case when we come across the situation of the curse of dimensionality (when $p>n$, $rank(X)<p$) or when we belive the variables are highly correlated, then both lasso or ridge regressions could be used to solve these problems. 

The Lasso regression allows us to do variable selection and estimation at the same time. However, the Lasso solution is not always unique if $rank(X)<p$, which means it could give an unstable solution for a subset of features, hence we will need to view the solution path of Lasso to find the optimal solution. The LARS algorithm from the `glmnet` package could help us in finding this path for any predictor matrix $X$.

If we believe that some of the features do in fact have some effect on the prediction, then we will do a ridge regression to cater to this situation. However, the ridge regression may only shrink some of the coefficient estimates, which may not necessarily solve the curse of dimensionality, although we are guaranteed a stable solution. 

To perform these regressions, we could use the same transformation using `broom` and perform the analyses using `lm.ridge()` function from `MASS` and `lasso()` from `glmnet` after tuning the penalty parameter.


(c) Random Forest

We could also do feature selection and estimation using the random forest algorithm from the `randomForest` package. To view the importance of the variables, we could do MeanDecreaseGini or MeanDecreaseAccuracy plot to see the effects of the variables on the prediction. We could attempt to tune the parameters prematurely for the `mtry` and `nodesize` arguments.

(d) **Feature Selection: PCA**

We could attempt to find the features that greatly affect the prediction. However, since we have features of only factor variables, computing the distance matrices may be a problem. As such , we could use the `FactoMineR` package to solve this problem. The package allows us choose the number of variables we would need using the `AFDM()` function.

Optional (Spare Time): **Classification**

If we have enough time, we could classify the tweets into any class we are interested in like "Trump vs Hillary", "Offensive vs Non-Offensive" and such.


#### 3) Visualizing the Data

> The greatest value of a picture is when it forces us to see what we never expected to see. 
>
> --- **John Tukey**

We are most interested in predicting the trends overtime given our features, hence we will mainly produce time series plots and compare the prediction using the different methods that we have outlined. 

Of course, we will include any other plots that we find interesting, as long as they are at most 3-dimensional plots. Ultimately, we will be following this philosophy:

> Visualization is often used for evil - twisting insignificant data changes and making them look meaningful. ... . Present results clearly and honestly. If something isn't working, those reviewing the results need to know.
> 
> --- **John Tukey**

***

## Challenges

The challenges that we will likely face are:

i) **Noninvertibility**

Since the document term matrix often times has more features than observations, we will likely encounter a problem when our objective function is unsolvable. Hence, we have to spend adequate time to perform feature selection or dimension reduction methods to solve the problem. Lasso regression will probably be our best bet since it almost always guarantees a solution in which $n>p$.

ii) **Computing the distance matrix**

As mentioned previously, calculating the distance matrix for this dataset may not be as simple as computing a Euclidean distance matrix since we are dealing with categorical variable. If we could determine that the features that we are dealing with could be classified as at least "integer-valued", then we would not need to worry about this problem.




